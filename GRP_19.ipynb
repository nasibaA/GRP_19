{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a95cdce",
   "metadata": {},
   "source": [
    "- What do you remember about PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5476f",
   "metadata": {},
   "source": [
    "Principal Componenet Analysis or PCA is a dimensionality-reduction method that is often used to reduce the dimensionality of large data sets, by transforming a large set of variables into a smaller one that still contains most of the information on the large set.\n",
    "\n",
    "in my word- if data has more than 3 dimensions, visualizing it is very hard. This is when PCA can help by consolidating features or variables that are highly correlated into so-called principal components. thereby PCA will show us in two damantion plot "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1898c0f3",
   "metadata": {},
   "source": [
    "- what is a multilayer perceptron?\n",
    "\n",
    "A multilayer perceptron is a class of neural network that is made up of at least 3 nodes. So now you can see the difference. Also, each of the node of the multilayer perceptron, except the input node is a neuron that uses a non-linear activation function.\n",
    "The nodes of the multilayer perceptron are arranged in layers.\n",
    "\n",
    "The input layer\n",
    "The output layer\n",
    "Hidden layers: layers between the input and the output\n",
    "\n",
    "\n",
    "- which approach to imporoving model stability was the most successful for the example in the reading ? why do you think that was?\n",
    "\n",
    "Multilayer Perceptron With Normalized Input Variables - performanced best.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b02559",
   "metadata": {},
   "source": [
    "1. Take one of the supervised learning models you have built recently and apply at least\n",
    "three dimensionality reduction techniques to it (separately). Be sure to create a short\n",
    "summary of each technique you use. Indicate how each changed the model\n",
    "performance. Reference:\n",
    "https://machinelearningmastery.com/dimensionality-reduction-algorithms-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df840b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7359307359307359\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "diabetes_df = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "X = diabetes_df.drop('Outcome', axis=1)\n",
    "y = diabetes_df['Outcome']\n",
    "\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)\n",
    "\n",
    "#Standardize\n",
    "sc= StandardScaler()\n",
    "X_train_sc=sc.fit_transform(X_train)\n",
    "X_test_sc=sc.fit_transform(X_test)\n",
    "\n",
    "#logistic regression\n",
    "clr = LogisticRegression(random_state=42).fit(X_train_sc,y_train)\n",
    "\n",
    "#predict\n",
    "y_predicted = clr.predict(X_test_sc)\n",
    "# print(y_predicted)\n",
    "\n",
    "print(clr.score(X_test_sc,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45be20bd",
   "metadata": {},
   "source": [
    "Principal Component Analysis\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/ https://www.datacamp.com/community/tutorials/principal-component-analysis-in-python\n",
    "\n",
    "PCA is used to reduce the number of features by finding the related components in the dataset and removing the non-essential components. It projects the high dimensional original data into a lower dimensional subspace.\n",
    "\n",
    "PCA on the diabetes dataset - A PCA with 6 components gave an accuracy score of 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0ba4544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7489177489177489"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca= PCA(n_components=6,random_state=42)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca= pca.fit_transform(X_test)\n",
    "\n",
    "clr = LogisticRegression(random_state=42).fit(X_train_pca,y_train)\n",
    "clr.score(X_test_pca, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba84344",
   "metadata": {},
   "source": [
    "Linear Discriminant Analysis\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html https://machinelearningmastery.com/linear-discriminant-analysis-for-dimensionality-reduction-in-python/\n",
    "\n",
    "LDA is most often used for multi-class classification problems. LDA reduces the number of input variables in the dataset.\n",
    "\n",
    "LDA on the diabetes dataset - Because the diabetes dataset has 2 classes, the maximum number of components to use is 1. We found that LDA gave an accuracy score of 0.37 - this makes sense as this technique is not used for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02f65df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36796536796536794"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda =  LinearDiscriminantAnalysis(n_components=1)\n",
    "\n",
    "X_train_lda = lda.fit_transform(X_train_sc,y_train)\n",
    "X_test_lda = lda.fit_transform(X_test_sc,y_test)\n",
    "\n",
    "clr = LogisticRegression(random_state=42).fit(X_train_lda,y_train)\n",
    "clr.score(X_test_lda, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45cbcc",
   "metadata": {},
   "source": [
    "Singular Value Decomposition\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html https://machinelearningmastery.com/singular-value-decomposition-for-machine-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb67e83e",
   "metadata": {},
   "source": [
    "SVD breaks a matrix down to its component parts. For the diabetes dataset, SVD produced an accuracy score of 0.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcd6a343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70995670995671"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=6)\n",
    "\n",
    "X_train_svd = svd.fit_transform(X_train,y_train)\n",
    "X_test_svd = svd.fit_transform(X_test,y_test)\n",
    "\n",
    "clr = LogisticRegression(random_state=42).fit(X_train_svd,y_train)\n",
    "clr.score(X_test_svd, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84e248",
   "metadata": {},
   "source": [
    "2. Write a function that will indicate if an inputted IPv4 address is accurate or not.\n",
    "IP addresses are valid if they have 4 values between 0 and 255 (inclusive), punctuated\n",
    "by periods.\n",
    "Input 1:\n",
    "2.33.245.5\n",
    "Output 1:\n",
    "True\n",
    "Input 2:\n",
    "12.345.67.89\n",
    "Output 2:\n",
    "False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8d5ea344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def IPv4_address(address): \n",
    "    import numbers\n",
    "    if address.count(\".\") !=3:\n",
    "        return False\n",
    "    elif address == \"\":\n",
    "        return False\n",
    "    else:\n",
    "        lst_split_address = address.split(\".\")\n",
    "        for k in lst_split_address:\n",
    "            if k.isnumeric() == False:\n",
    "                return False\n",
    "                break\n",
    "        slice_split_address = [int(num) for num in lst_split_address[0:]]\n",
    "        m=0\n",
    "        for u in slice_split_address:\n",
    "            if u > 255:\n",
    "                return False\n",
    "            else:\n",
    "                m = m + 1\n",
    "        if m == 4:\n",
    "            return True\n",
    "        else:\n",
    "            return False                   \n",
    "IPv4_address('300.56.87.200')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
